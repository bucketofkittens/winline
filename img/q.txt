Если я правильно понял, то задача – это wharehouse, по которому нужно осуществлять поиск по большому числу критериев в любых комбинациях. Причём здесь значения критериев только бинарные, что, на мой взгляд, какое-то нереальное упрощение. 
  
В принците я 7 лет назад реализовывал warehouse, в котором было более 300 признаков. Поиск можно было осуществлять по 20-ти критериям. Работало это на Oracle 10g в простейшей конфигурации. В таких задачах самое сложное – это наполнение и изменение данных. Проблем со скоростью запросов обычно нет. Надо смотреть на то, как работают с данными. 
Инструменты для обеспечения быстрой выборки данных, например у Oracle, имеются. По приведенному примеру можно сделать demo, если нужно. 
  
Если решать задачу средствами базы данныз «в лоб», как описано, то картина такая... 
Производительность поиска, требующего постоанное СКАНИРОВАНИЕ всего набора данных, определяется размером строки и скоростью диска. 
Допустим, у нас еть описание продукта и 20 двоичных признаков. Размер строки будет в худшей реализации 120 байт. 
Скорость сканирования диска у одного SSD – 300 Мб/с (не самый быстрый диск). 
Получаем: 300*1024*1024/120 = 2,621,400 строк в секунду. 
Если диски объединить в RAID, то по писсимистичным оценком производительность будет расти с коэффициентом 1.5. 
  
Вот только такая задача не решается в базе данных СКАНИРОВАНИЕМ. 
  
Если мы, к примеру, используем Oracle 11g, то на каждый признак, участвующий в поиске делается bitmap индекс. 
Каждый индекс, во-первых, хранит только возможные значения и маску того, как эти значения распределены по строкам (1 бит на строку), во-вторых, при запросе происходит не СРАНИРОВАНИЕ индекса а двоичный поиск, в-третих, обращение к самой таблице будет только после того, как результаты поиска по индексам «соединяться» и получится адрес строк, удовлетворяющих всем критериям. 
  
Лимитирующим фактором в таких системах обычно является интенсивность вставки/обновления. 
Надо смотреть на то, как работает система. 
Но чтобы сделать OLTP, вставляющуюю по 1000 записей в секунду, надо будет подумать =) 
  
Если нужно, я могу сделать demo за пару часов. 
  

 
Classification: For internal use only

Классическая База Данных(БД) работает примерно по такому принципу.
Имеем например 100 объектов, которые характеризуются например 3 признаками:
1. Есть в наличии или нет.
2. Тяжелый или лекгий.
3. Скоропортящийся или нет.

В общей сложности можно построить 2 в степени 3(2^3) = 8 разных комбинаций из данных признаков

1. есть на складе, тяжелый, скоропорт
2. есть на складе, легкий, скоропорт
3. есть на складе, тяжелый, не скоропорт
4. есть на складе, легкий, не скоропорт
5. нет на складе, тяжелый,скоропорт
6. нет на складе, легкий, скоропорт
7. нет на складе, тяжелый, не скоропорт
8. нет на складе, легкий, не скоропорт

БД обычно вычисляет сколько всевозможных комбинаций призаков существует,
и каждой комбианции из признаков, присаивает товары( объекты) описание которых соответствует
этой комбинации признаков.

Например Комбинации номер 1 будут соответствовать следущие товары: арбуз,дыня
2 - яблоко, груша итд.
.....
8 - утюг,кофеварка


Человек вводит в поиск например( ставит так галочки), что получается комбинация 2 и БД ему выдает
ответ яблоко груша.

Это самая быстрая теоретически возможная выборка данных. Но есть ограничение.
Когда признаков 32, комбинаций этих признаков становится 2^32= 4 миллиарда.
Если хранить все в оперативной памяти, то сегодня доступные в продаже серверы имеют максимальную 
память в 32 Гигабайта, что теоретически позволяют 35 признаков поиска.
Например для 64 признаков поиска потребуется Оперативная память размером в Терабайты.


Сегодня по сравнению с 60 годами процессоры стали намного быстрее. 
Миллиард операций за секунду.
Мы просто сканируем объекты поиска на признаки. 
Например 64 признаков поиска. Каждому объекту присваиваем в памяти 8 байт, 
где каждый бит равен 0 если признака такого нет и 1 если объект имеет этот признак.

Такой метод имеет свои плюсы и минусы. Когда речь идет об очень много объектов поиска
(больше миилиона и малым количеством признаков например мужчина или женщина) то намного
эффективнее использовать классическую БД.
Когда же речь идет о многих признаков поиска: ФИО, год рождения, образование, дети, рост,
цвет глаз, пол итд то эфекективнее использовать быстрое сканирование.
Тем Более ФИО это не один признак, а более 30 сразу.
Быстрое сканирование ограниченно количеством объектов поиска, а классическая БД ограничено
количесвтом признаков.
Для быстрого сканирования решение или выход из ситуации проще. Можно подсоеденить 
один два компа и тогда скорость возрастает пропорционально.
Для классической БД выход один - создается таблица не в памяти комьютера,
а на жестком носителе или подсоединяют или подсоединение любого нового сервера не 
дает пропорционального роста. К тому же при быстром сканировании Оперативную память используем для 
хранения объекта и когда объект востребован, он высчитывается из Оперативной памяти, а при 
классической БД при загруженности он читается с винчестера, что замедляет очень сильно работу
с клиентами.

Сканирование ограниченно скоростью чтения из памяти, а классическая БД скоростью винчестеров,
и объемом памяти.

Также нас устраивает использовать наш двигатель, так нет кучи настроек и требований которые существуют
в классических БД